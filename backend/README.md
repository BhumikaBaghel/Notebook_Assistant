# Notebook LM Clone - Backend

FastAPI backend with LangChain integration for document processing and AI-powered analysis.

## ğŸ› ï¸ Tech Stack

- **Framework**: FastAPI with async support
- **AI/ML**: LangChain + OpenAI GPT-4/Claude
- **Database**: PostgreSQL (metadata) + Vector Database (embeddings)
- **Package Manager**: UV
- **Python Version**: 3.13

## ğŸš€ Setup

```bash
# Install dependencies
uv install

# Run development server
uv run python main.py

# Add new dependencies
uv add <package-name>
```

## ğŸ“ Project Structure (Planned)

```
backend/
â”œâ”€â”€ main.py                 # FastAPI application entry point
â”œâ”€â”€ pyproject.toml         # Dependencies and project metadata
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ api/               # API routes
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ documents.py   # Document upload/management
â”‚   â”‚   â”œâ”€â”€ chat.py        # Q&A and chat endpoints
â”‚   â”‚   â””â”€â”€ notebooks.py   # Notebook management
â”‚   â”œâ”€â”€ core/              # Core functionality
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ config.py      # Configuration management
â”‚   â”‚   â”œâ”€â”€ database.py    # Database connection
â”‚   â”‚   â””â”€â”€ security.py    # Authentication (future)
â”‚   â”œâ”€â”€ models/            # Database models
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ document.py    # Document models
â”‚   â”‚   â””â”€â”€ conversation.py # Chat models
â”‚   â”œâ”€â”€ services/          # Business logic
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ document_processor.py # Document processing
â”‚   â”‚   â”œâ”€â”€ embedding_service.py  # Vector embeddings
â”‚   â”‚   â””â”€â”€ ai_service.py         # LangChain integration
â”‚   â””â”€â”€ utils/             # Utility functions
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ file_utils.py
â””â”€â”€ tests/                 # Test files
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ test_documents.py
    â””â”€â”€ test_ai_service.py
```

## ğŸ”§ Development

### Current Status
- âœ… Basic FastAPI setup
- â³ Application structure
- â³ Document upload endpoints
- â³ LangChain integration
- â³ Vector database setup

### Next Steps (Phase 1)
1. Create FastAPI application structure
2. Add document upload endpoints
3. Implement text extraction for PDF/DOCX/TXT
4. Set up vector database integration
5. Create basic CRUD operations

### Dependencies to Add
```bash
uv add langchain langchain-openai
uv add sqlalchemy alembic psycopg2-binary
uv add chromadb  # or pinecone-client
uv add python-multipart  # for file uploads
uv add pydantic-settings
```

## ğŸ“Š API Endpoints (Planned)

- `GET /health` - Health check
- `POST /documents/upload` - Upload documents
- `GET /documents/` - List documents
- `POST /chat/` - Q&A over documents
- `GET /documents/{id}/summary` - Document summary
- `POST /notebooks/` - Create notebook
- `GET /notebooks/{id}` - Get notebook content

## ğŸ§ª Testing

```bash
# Run tests
uv run pytest

# Run with coverage
uv run pytest --cov=app
```

## ğŸ”— Related

- [Project Roadmap](../PROJECT_ROADMAP.md)
- [Frontend Documentation](../frontend/README.md) (to be created)
- [API Documentation](http://localhost:8000/docs) (when running)